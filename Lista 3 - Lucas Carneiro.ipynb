{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista 3 - Lucas Carneiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import machado\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Primeiro passo é organizar o corpus a ser utilizado.\n",
    "\n",
    "A base escolhida foram os documentos de Machado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos = [machado.raw(id) for id in machado.fileids()]\n",
    "swu = stopwords.words('portuguese') + list (string.punctuation)\n",
    "stemmer = PortugueseStemmer()\n",
    "\n",
    "textos_limpos = []\n",
    "for texto in textos:\n",
    "    tlimpo = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos_limpos.append(tlimpo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados limpos criaremos um corpus adequado a utlização pelo gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(textos_limpos)\n",
    "corpus = [dictionary.doc2bow(text) for text in textos_limpos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do corpus gerado, construiremos o modelo LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construção de modelo TFIDF\n",
    "mod_tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = mod_tfidf[corpus]\n",
    "\n",
    "#Construção de modelo LSI\n",
    "mod_lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=200)\n",
    "corpus_lsi = mod_lsi[corpus_tfidf] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O assunto escolhido será o sexto tópico de nosso modelo.\n",
    "\n",
    "O critério utilizado foi escolher o tópico com interpretação mais intuitiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cecíl', -0.56734219735659397),\n",
       " ('luís', 0.42830216709079988),\n",
       " ('alves', 0.20137512502482588),\n",
       " ('venânci', -0.13207811179097584),\n",
       " ('carlot', -0.12329779767923273),\n",
       " ('major', 0.11894631801783583),\n",
       " ('magalhã', -0.11637546023256877),\n",
       " ('albert', 0.11481660552969455),\n",
       " ('tibúrci', -0.10886793623477728),\n",
       " ('marcelin', 0.10287118355012496)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topico = 5\n",
    "mod_lsi.show_topic(topico,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constriremos o nosso conjunto relevante como sendo os 25 documentos mais influenciados pelo tópico escolhido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i,texto in enumerate(corpus_lsi):\n",
    "    lista.append((texto[topico][1],i))\n",
    "\n",
    "R_relevantes = []\n",
    "n_relevantes = 25\n",
    "for i in sorted(lista,reverse = True)[:n_relevantes]:\n",
    "    R_relevantes.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 133, 15, 158, 163, 38, 45, 55, 57, 59, 190, 191, 64, 192, 193, 71, 205, 81, 210, 83, 82, 84, 93, 224, 235}\n"
     ]
    }
   ],
   "source": [
    "R_relevantes = set(R_relevantes)\n",
    "print(R_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos também a nossa consulta utilizando os 10 termos mais pertinentes ao nosso tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_relevantes = 10\n",
    "q_consulta = []\n",
    "for t in mod_lsi.show_topic(topico,10):\n",
    "    q_consulta.append(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cecíl', 'luís', 'alves', 'venânci', 'carlot', 'major', 'magalhã', 'albert', 'tibúrci', 'marcelin']\n"
     ]
    }
   ],
   "source": [
    "print(q_consulta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começaremos por gerar o índice invertido do nosso corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indice = defaultdict(lambda:set([]))\n",
    "for tid,t in enumerate(textos_limpos):\n",
    "    for term in t:\n",
    "        indice[term].add(tid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esse exercício será utilizada a seguinte função de busca booleana que retorna todos os documentos que possuem pelo menos um dos termos pesquisados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_adv(search, indice):\n",
    "\n",
    "    resultado = indice[search[0]]\n",
    "    for token in search[1:]:\n",
    "            resultado = resultado | indice[token]\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 4, 5, 11, 12, 13, 15, 16, 18, 21, 23, 24, 25, 26, 27, 28, 29, 33, 34, 36, 38, 39, 40, 43, 45, 48, 49, 50, 51, 52, 54, 55, 57, 59, 60, 61, 63, 64, 66, 67, 71, 76, 80, 81, 82, 83, 84, 92, 93, 95, 96, 105, 107, 110, 113, 120, 121, 122, 128, 139, 140, 151, 154, 158, 161, 162, 163, 165, 168, 171, 174, 175, 176, 179, 182, 183, 185, 187, 188, 190, 191, 192, 193, 205, 210, 217, 218, 219, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 235, 236, 237, 238, 240, 241, 242, 244, 245}\n"
     ]
    }
   ],
   "source": [
    "resp_boo = busca_adv(q_consulta,indice)\n",
    "resp_boo = set(resp_boo)\n",
    "print(resp_boo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanto ao tf_idf, faremos a busca da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = nltk.TextCollection(textos_limpos)\n",
    "\n",
    "tfidf_matrix = np.zeros((len(textos_limpos),len(q_consulta)))\n",
    "\n",
    "for j, termo in enumerate(q_consulta):\n",
    "    for i, texto in enumerate(textos_limpos):\n",
    "        tfidf_matrix[i,j] = T.tf_idf(termo,texto)\n",
    "        \n",
    "Mtfidf_Norm = np.array([r/norm(r) if norm(r) !=0 else np.zeros(len(r)) for r in tfidf_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir os documentos encontrados utilizaremos o método de truncagem com valor estabelecido em (>=) 0,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordem(q,MN):\n",
    "    return [np.dot(q,r) for r in MN]\n",
    "\n",
    "vetor_tfidf = np.array([T.tf_idf(w,q_consulta) for w in q_consulta])\n",
    "vetor_tfidf /= norm(vetor_tfidf)\n",
    "resp_tfidf = ordem(vetor_tfidf,Mtfidf_Norm)\n",
    "\n",
    "vtfidf = filter(lambda x : x[0]!=0.0, zip(resp_tfidf,range(len(textos_limpos))))\n",
    "\n",
    "temp_tfidf = sorted(vtfidf, reverse=True)\n",
    "\n",
    "trunc = 0.3\n",
    "resp_tfidf = []\n",
    "for i in temp_tfidf:\n",
    "    if i[0]>= trunc:\n",
    "        resp_tfidf.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 2, 11, 140, 13, 139, 15, 26, 158, 161, 33, 34, 165, 38, 168, 48, 52, 182, 183, 185, 57, 187, 191, 193, 66, 67, 82, 217, 219, 93, 95, 224, 225, 223, 235, 236, 237, 241, 120, 122}\n"
     ]
    }
   ],
   "source": [
    "resp_tfidf = set(resp_tfidf)\n",
    "print(resp_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora reutilizaremos a função para cálculo de Revocação e Precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RevPre(parcial,geral):\n",
    "    \n",
    "    #parcial = 'documentos encontrados'\n",
    "    #geral = 'documentos relevantes'\n",
    "    \n",
    "    rev = len(parcial & geral)/len(geral)\n",
    "    pre = len(parcial & geral)/len(parcial)\n",
    "    \n",
    "    print('Revocação = ' + str(rev))\n",
    "    print('Precisão = ' + str(pre))\n",
    "    \n",
    "    #return rev,pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para a busca booleana\n",
      "Revocação = 0.96\n",
      "Precisão = 0.21818181818181817\n",
      "\n",
      "\n",
      "Resultados para a busca por tf_idf\n",
      "Revocação = 0.4\n",
      "Precisão = 0.25\n"
     ]
    }
   ],
   "source": [
    "print('Resultados para a busca booleana')\n",
    "RevPre(resp_boo,R_relevantes)\n",
    "print('\\n')\n",
    "print('Resultados para a busca por tf_idf')\n",
    "RevPre(resp_tfidf,R_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo a função de busca probabilística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_busca(query, indice, relevantes, N_docs = 246):\n",
    "    \n",
    "    #query = consulta a ser realizada\n",
    "    #indice = indice invertido\n",
    "    #relevantes = conjunto de documentos atualmente considerados relevantes\n",
    "    #N_docs = número de documentos presente no corpus\n",
    "    \n",
    "    query_tok = query #[stemmer.stem(token.lower())  for token in WordPunctTokenizer().tokenize(query) if token not in swu]\n",
    "    \n",
    "    ct = []\n",
    "    S = len(relevantes)\n",
    "    N = N_docs\n",
    "    \n",
    "    for termo in query_tok:\n",
    "        s = len(indice[termo] & relevantes)\n",
    "        df = len(indice[termo])\n",
    "        \n",
    "        up = s/(S - s +0.5)\n",
    "        down =(df - s)/(N - df - S + s -0.5)\n",
    "        \n",
    "        ct.append(np.log(up/down))\n",
    "    \n",
    "    RSVs = []\n",
    "    for doc in range(N):\n",
    "        rsv = 0\n",
    "        for pos,termo in enumerate(query_tok):\n",
    "            if doc in indice[termo]:\n",
    "                rsv += ct[pos]\n",
    "        RSVs.append((rsv,doc))\n",
    "        \n",
    "    resultado = sorted(RSVs,reverse=True)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9.5992284489099688, 191), (9.5297251576714537, 193), (8.0967590183874858, 57), (7.9042516335644954, 82), (7.8347483423259785, 1), (7.0256565673047344, 13), (6.899111083505626, 237), (6.899111083505626, 15), (6.568748768711731, 229), (6.090019308484381, 93)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Casa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "temp_prob = prob_busca(q_consulta,indice,R_relevantes)\n",
    "print(temp_prob[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note-se que o parâmetro 'relevantes' é na verdade o conjunto de documentos considerados relevantes naquele momento, sendo portanto um conjunto que deve ser atualizado conforme a resposta do usuário.\n",
    "\n",
    "O parâmetro 'N_docs' é a quantidade de documentos no corpus utilizado sendo então praticamente fixo.\n",
    "Pode ser obtido através do 'indice' mas considerei que retardaria a função desnecessáriamente.\n",
    "\n",
    "Para calcular a Revocação e a Precisão, novamente usaremos o método de truncagem, considerando como resposta os documentos com RSV acima de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 128, 4, 12, 13, 15, 21, 23, 151, 25, 24, 27, 28, 29, 158, 161, 34, 163, 36, 165, 38, 39, 168, 40, 45, 175, 176, 49, 51, 182, 183, 55, 57, 59, 187, 188, 61, 191, 192, 193, 66, 64, 63, 190, 67, 71, 205, 81, 82, 210, 83, 84, 217, 219, 92, 93, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 96, 105, 235, 237, 238, 240, 113, 244, 120, 122}\n"
     ]
    }
   ],
   "source": [
    "trunc = 1\n",
    "resp_prob = []\n",
    "for i in temp_prob:\n",
    "    if i[0] >= trunc:\n",
    "        resp_prob.append(i[1])\n",
    "        \n",
    "resp_prob = set(resp_prob)\n",
    "print(resp_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revocação = 0.96\n",
      "Precisão = 0.3037974683544304\n"
     ]
    }
   ],
   "source": [
    "RevPre(resp_prob,R_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular a probabilidade p_termo para cada termo de nossa consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_termo = []\n",
    "S = len(R_relevantes)\n",
    "for termo in q_consulta:\n",
    "    s = len(indice[termo] & R_relevantes)\n",
    "    p_termo.append((termo,s/S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cecíl', 0.04), ('luís', 0.84), ('alves', 0.24), ('venânci', 0.0), ('carlot', 0.16), ('major', 0.36), ('magalhã', 0.08), ('albert', 0.2), ('tibúrci', 0.04), ('marcelin', 0.16)]\n",
      "\n",
      "\n",
      "[('cecíl', -0.56734219735659397), ('luís', 0.42830216709079988), ('alves', 0.20137512502482588), ('venânci', -0.13207811179097584), ('carlot', -0.12329779767923273), ('major', 0.11894631801783583), ('magalhã', -0.11637546023256877), ('albert', 0.11481660552969455), ('tibúrci', -0.10886793623477728), ('marcelin', 0.10287118355012496)]\n"
     ]
    }
   ],
   "source": [
    "print(p_termo)\n",
    "print('\\n')\n",
    "print(mod_lsi.show_topic(topico,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda que os vetores sejam aparentemente distintos é possivel perceber uma correlação em termos de ordem de significância.\n",
    "\n",
    "Os termos com menor relevância para o tópico, também apresentam uma probabilidade menor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetindo o procedimento o exercício anterior.\n",
    "\n",
    "Definimos a nova função de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def okapi_busca(query, indice, corpo):\n",
    "    \n",
    "    #query = consulta a ser realizada\n",
    "    #indice = indice invertido\n",
    "    #corpo = corpus\n",
    "    \n",
    "    query_tok = query #[stemmer.stem(token.lower())  for token in WordPunctTokenizer().tokenize(query) if token not in swu]\n",
    "    \n",
    "    N = len(corpo)\n",
    "    \n",
    "    L = []\n",
    "    for texto in corpo:\n",
    "        L.append(len(texto))\n",
    "        \n",
    "    L_ave = sum(L)/N\n",
    "    k1 = 1.2\n",
    "    b = 0.75\n",
    "    \n",
    "    RSVs = []\n",
    "    for doc in range(N):\n",
    "        rsv = 0\n",
    "        \n",
    "        for termo in query_tok:\n",
    "            if doc in indice[termo]:\n",
    "                tf = 1 #pode ser alterado para melhor representar a frequencia\n",
    "            df = len(indice[termo])\n",
    "        rsv += np.log(N/df)*((k1 + 1)*tf)/(k1*(1 - b + (b*(L[doc]/L_ave))) + tf)\n",
    "        \n",
    "        RSVs.append((rsv,doc))\n",
    "        \n",
    "    resultado = sorted(RSVs,reverse=True)\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6.2393542810351423, 199), (6.2027710326330876, 211), (6.2007879168888991, 204), (6.1522693329462017, 197), (6.1490184201635358, 170), (6.1354020203837338, 177), (6.1051446611116287, 169), (6.069480689933819, 201), (6.0618925523896925, 209), (6.0336052313313404, 212)]\n"
     ]
    }
   ],
   "source": [
    "temp_okapi = okapi_busca(q_consulta,indice, textos_limpos)\n",
    "print(temp_okapi[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando método de truncagem para definir a resposta da função de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 128, 4, 12, 13, 15, 21, 23, 151, 25, 24, 27, 28, 29, 158, 161, 34, 163, 36, 165, 38, 39, 168, 40, 45, 175, 176, 49, 51, 182, 183, 55, 57, 59, 187, 188, 61, 191, 192, 193, 66, 64, 63, 190, 67, 71, 205, 81, 82, 210, 83, 84, 217, 219, 92, 93, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 96, 105, 235, 237, 238, 240, 113, 244, 120, 122}\n"
     ]
    }
   ],
   "source": [
    "trunc_okapi = 1\n",
    "resp_okapi = []\n",
    "for i in temp_okapi:\n",
    "    if i[0] >= trunc_okapi:\n",
    "        resp_okapi.append(i[1])\n",
    "        \n",
    "resp_okapi = set(resp_okapi)\n",
    "print(resp_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, finalmente, calculando a Revocação e a Precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revocação = 0.96\n",
      "Precisão = 0.09836065573770492\n"
     ]
    }
   ],
   "source": [
    "RevPre(resp_okapi,R_relevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se ganhos consideráveis no algoritmo Okapi em relação aos outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
